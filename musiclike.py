# -*- coding: utf-8 -*-
"""musiclike.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mu_96h8FF_-IoP_gk-DJoaInmHEMtTZm

**BU PROJEDE NEYİ AMAÇLIYORUZ?**

Bu veri seti, kullanıcıların müzik tercihlerini analiz ederek bir şarkının beğenilip beğenilmeyeceğini tahmin etmeye odaklanıyor.
Bu tahminler, çeşitli müzik özelliklerine dayanarak yapılır.

1.   Danceability: Dans edilebilirlik
2.   Energy: Enerji
3.   Key: Müzikal anahtar (nota)
4.   Loudness: Gürültü seviyesi (desibel)
5.   Mode: Müzikal mod (majör/minör)
6.   Speechiness: Konuşma oranı
7.   Acousticness: Akustik oranı
8.   Instrumentalness: Enstrümantal oran
9.   Liveness: Canlılık oranı
10.  Valence: Neşe oranı (pozitiflik)
11.  Tempo: Tempo (bpm - dakika başına vuruş)
12.  Duration_ms: Süre (milisaniye cinsinden)
13.  Time_signature: Ölçü (müzikal ölçü)
14.  Liked: Beğenildi mi (1: Evet, 0: Hayır)

**Problem**, bu özelliklere göre bir şarkının beğenilip beğenilmediğini (liked sütunu: 1 veya 0) tahmin etmek. Modelleri eğittikten sonra, yeni şarkılar için müzik platformlarında öneri sistemleri geliştirebilir ya da müzik prodüktörlerine şarkıların popüler olma potansiyelini değerlendirmelerinde yardımcı olabiliriz.

**Özellik seçimi**

**Korelasyon Analizi**: Hedef değişkenle en yüksek korelasyona sahip olan özellikleri seçer.
**Random Forest ile Önem Sıralaması**: Rastgele orman modeliyle öznitelik önemini belirler.
**RFE (Recursive Feature Elimination):** Lojistik regresyon ile en iyi özellikleri seçmek için eleme yapar.

**Modellerin Rolü**

Lojistik Regresyon, KNN ve Karar Ağaçları: Bu modeller, verilen müzik özelliklerine dayanarak şarkının beğenilip beğenilmeyeceğini sınıflandırır.

**Çıktılar**

Modellerin performansını karşılaştırarak hangi modelin en doğru tahmini yaptığını bulabiliriz.

Her bir modelin doğruluk, hassasiyet, duyarlılık gibi metrikleriyle performansını değerlendirebiliriz.

*Yani, projenin sonunda elimizde hangi modelin daha iyi performans gösterdiğini belirleyen bir sınıflandırma analizi olacak.*
"""

import pandas as pd

# Veriyi yükleme
data_path = 'data.csv'
data = pd.read_csv(data_path)

# İlk birkaç satırı göster
print(data.head())

# Veri tiplerini kontrol et
print(data.dtypes)

# Kategorik değişkenlerin sayısallaştırılması
# Örneğin, 'liked' dışındaki diğer kategorik sütunlar varsa:
categorical_columns = data.select_dtypes(include=['object']).columns

# Get dummies ile sayısallaştırma işlemi
data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)

# Sayısallaştırılmış veri setinin ilk birkaç satırını göster
print(data.head())

import seaborn as sns
import matplotlib.pyplot as plt

# Sayısal sütunları tanımla
numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns

# Her bir sütun için box plot çiz
plt.figure(figsize=(15, 10))
for i, col in enumerate(numeric_columns, 1):
    plt.subplot(4, 4, i)
    sns.boxplot(data[col])
    plt.title(col)

plt.tight_layout()
plt.show()
plt.close()

# Tüm sayısal sütunlar için Z-skoru yöntemiyle aykırı değer temizleme öncesi ve sonrası kutu grafiği
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Z-skoru yöntemiyle aykırı değerleri tespit ve temizleme fonksiyonu
def remove_outliers_zscore(df, col, threshold=3):
    """
    Z-skoru ile aykırı değerleri tespit ve temizleme fonksiyonu.
    - df: Veri çerçevesi (pandas DataFrame)
    - col: Aykırı değerlerin kontrol edileceği sütun ismi (string)
    - threshold: Z-skoru eşiği (genellikle 3 veya 4 kullanılır)
    """
    mean = df[col].mean()
    std = df[col].std()
    z_score = (df[col] - mean) / std

    return df[np.abs(z_score) < threshold]

# Tüm sayısal sütunlar için Z-skoru öncesi ve sonrası kutu grafiği
def plot_before_after_zscore(df, numeric_columns, threshold=3):
    """
    Her sayısal sütun için Z-skoru yöntemiyle aykırı değer temizleme öncesi ve sonrası grafikleri çiz.
    - df: Veri çerçevesi (pandas DataFrame)
    - numeric_columns: Sayısal sütunların isimlerini içeren liste (List of strings)
    - threshold: Z-skoru eşiği (genellikle 3 veya 4 kullanılır)
    """
    num_cols = len(numeric_columns)
    fig, axes = plt.subplots(num_cols, 2, figsize=(4, 2 * num_cols))

    for i, col in enumerate(numeric_columns):
        # Temizleme öncesi grafiği
        sns.boxplot(df[col], ax=axes[i, 0])
        axes[i, 0].set_title(f'{col} (Önce)')

        # Z-skoru yöntemiyle temizle ve sonrası grafiği
        clean_df = remove_outliers_zscore(df, col, threshold)
        sns.boxplot(clean_df[col], ax=axes[i, 1])
        axes[i, 1].set_title(f'{col} (Sonra)')

    fig.tight_layout()
    plt.show()

# Tüm sayısal sütunlar için grafikleri göster
numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns
plot_before_after_zscore(data, numeric_columns)

"""**Normalizasyon ve test eğitim setlerini ayırma aşaması**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import pandas as pd

# Aykırı değerler temizlenmiş veri seti ve hedef değişkeni
X = data.drop(columns='liked')
y = data['liked']

# Eğitim ve test setlerine ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Min-Max Normalizasyon işlemi
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Normalleştirilmiş eğitim ve test setlerinin ilk birkaç satırını göster
train_df = pd.DataFrame(X_train_scaled, columns=X.columns).head()
test_df = pd.DataFrame(X_test_scaled, columns=X.columns).head()

print("Eğitim Seti (Normalleştirilmiş):")
print(train_df)

print("\nTest Seti (Normalleştirilmiş):")
print(test_df)

"""***Korelasyon Analizi***"""

import seaborn as sns
import matplotlib.pyplot as plt

# Korelasyon matrisini oluştur
corr_matrix = pd.DataFrame(X_train_scaled, columns=X.columns).corrwith(pd.Series(y_train))

# Hedef değişkenle en yüksek korelasyona sahip özellikleri göster
top_corr_features = corr_matrix.abs().sort_values(ascending=False).index
sns.heatmap(pd.DataFrame(X_train_scaled, columns=X.columns)[top_corr_features].corr(), annot=True, cmap='coolwarm')
plt.show()

"""***Random Forest***"""

from sklearn.ensemble import RandomForestClassifier
import pandas as pd

# Rastgele Orman modeliyle en önemli özellikleri bul
model_rf = RandomForestClassifier(random_state=42)
model_rf.fit(X_train_scaled, y_train)

# Özellik önemlerini göster
feature_importances_rf = pd.Series(model_rf.feature_importances_, index=X.columns).sort_values(ascending=False)
feature_importances_rf.plot(kind='bar', figsize=(6, 4))
plt.ylabel('Özellik Önemi')
plt.show()

"""***Recursive Feature Elimination***"""

from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

# Lojistik Regresyon modeli ile RFE uygulayın
model_lr = LogisticRegression(max_iter=1000, random_state=42)
rfe = RFE(model_lr, n_features_to_select=5)
rfe.fit(X_train_scaled, y_train)

# Seçilen özellikleri göster
selected_features_rfe = X.columns[rfe.support_]
print("RFE ile Seçilen Özellikler:", selected_features_rfe)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

# Model tanımlamaları
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier()
}

# Özellik setleri
feature_sets = {
    "Correlation": top_corr_features[:5],  # En yüksek korelasyonlu 5 özellik
    "Random Forest": feature_importances_rf.index[:5],  # En önemli 5 özellik
    "RFE": selected_features_rfe  # RFE'den seçilen özellikler
}

# Her özellik seti ve model için sonuçları sakla
results = {}

for feature_set_name, features in feature_sets.items():
    # Eğitim ve test setlerini ilgili özelliklere göre filtrele
    X_train_fs = pd.DataFrame(X_train_scaled, columns=X.columns)[features]
    X_test_fs = pd.DataFrame(X_test_scaled, columns=X.columns)[features]
    results[feature_set_name] = {}

    for model_name, model in models.items():
        # Modeli eğit ve test verisi üzerinde tahmin yap
        model.fit(X_train_fs, y_train)
        y_pred = model.predict(X_test_fs)

        # Doğruluk oranını hesapla
        accuracy = accuracy_score(y_test, y_pred)
        results[feature_set_name][model_name] = accuracy

        # Karışıklık matrisini hesapla
        cm = confusion_matrix(y_test, y_pred)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)

        # Karışıklık matrisini çiz
        plt.figure()
        disp.plot(cmap=plt.cm.Blues)
        plt.title(f"Confusion Matrix: {model_name} - {feature_set_name}")
        plt.show()

        print(f"Model: {model_name}, Feature Set: {feature_set_name}, Accuracy: {accuracy}")

# Başlangıçta boş bir liste oluştur
results = []

# Her özellik seti ve model için sonuçları topla
for feature_set_name, features in feature_sets.items():
    # Eğitim ve test setlerini ilgili özelliklere göre filtrele
    X_train_fs = pd.DataFrame(X_train_scaled, columns=X.columns)[features]
    X_test_fs = pd.DataFrame(X_test_scaled, columns=X.columns)[features]

    for model_name, model in models.items():
        # Modeli eğit ve test verisi üzerinde tahmin yap
        model.fit(X_train_fs, y_train)
        y_pred = model.predict(X_test_fs)

        # Doğruluk, kararlılık ve hassasiyet metriklerini hesapla
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')

        # Sonuçları listeye ekle
        results.append({
            "Feature Set": feature_set_name,
            "Model": model_name,
            "Accuracy": accuracy,
            "Precision": precision,
            "Recall": recall
        })

        # Karışıklık matrisini hesapla ve görselleştir
        cm = confusion_matrix(y_test, y_pred)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        plt.figure()
        disp.plot(cmap=plt.cm.Blues)
        plt.title(f"Confusion Matrix: {model_name} - {feature_set_name}")
        plt.show()

# Listeyi bir DataFrame'e dönüştür
results_df = pd.DataFrame(results)

# Tüm sonuçları göster
print(results_df)

